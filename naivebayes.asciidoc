+*In[7]:*+
[source, ipython3]
----
from collections import defaultdict
import numpy as np

# noinspection SpellCheckingInspection
class NaiveBayesClassifier(object):
    def __init__(self, n_gram=1, printing=False):
        self.prior = defaultdict(int)
        self.logprior = {}
        self.bigdoc = defaultdict(list)
        self.loglikelihoods = defaultdict(defaultdict)
        self.V = []
        self.n = n_gram

    def compute_prior_and_bigdoc(self, training_set, training_labels):
        '''
        Computes the prior and the bigdoc (from the book's algorithm)
        :param training_set:
            a list of all documents of the training set
        :param training_labels:
            a list of labels corresponding to the documents in the training set
        :return:
            None
        '''
        for x, y in zip(training_set, training_labels):
            all_words = x.split(" ")
            if self.n == 1:
                grams = all_words
            else:
                grams = self.words_to_grams(all_words)

            self.prior[y] += len(grams)
            self.bigdoc[y].append(x)

    def compute_vocabulary(self, documents):
        vocabulary = set()

        for doc in documents:
            for word in doc.split(" "):
                vocabulary.add(word.lower())

        return vocabulary

    def count_word_in_classes(self):
        counts = {}
        for c in list(self.bigdoc.keys()):
            docs = self.bigdoc[c]
            counts[c] = defaultdict(int)
            for doc in docs:
                words = doc.split(" ")
                for word in words:
                    counts[c][word] += 1

        return counts

    def train(self, training_set, training_labels, alpha=1):
        # Get number of documents
        N_doc = len(training_set)

        # Get vocabulary used in training set
        self.V = self.compute_vocabulary(training_set)

        # Create bigdoc
        for x, y in zip(training_set, training_labels):
            self.bigdoc[y].append(x)

        # Get set of all classes
        all_classes = set(training_labels)

        # Compute a dictionary with all word counts for each class
        self.word_count = self.count_word_in_classes()

        # For each class
        for c in all_classes:
            # Get number of documents for that class
            N_c = float(sum(training_labels == c))

            # Compute logprior for class
            self.logprior[c] = np.log(N_c / N_doc)

            # Calculate the sum of counts of words in current class
            total_count = 0
            for word in self.V:
                total_count += self.word_count[c][word]

            # For every word, get the count and compute the log-likelihood for this class
            for word in self.V:
                count = self.word_count[c][word]
                self.loglikelihoods[c][word] = np.log((count + alpha) / (total_count + alpha * len(self.V)))

    def predict(self, test_doc):
        sums = {
            0: 0,
            1: 0,
        }
        for c in self.bigdoc.keys():
            sums[c] = self.logprior[c]
            words = test_doc.split(" ")
            for word in words:
               if word in self.V:
                   sums[c] += self.loglikelihoods[c][word]

        return sums


# doc1 = "just plain boring"                      # -
# doc2 = "entirely predictable and lacks energy"  # -
# doc3 = "no surprises and very few laughs"       # -
# doc4 = "very powerful"                          # +
# doc5 = "the most fun film of the summer"        # +
#
# training_set = [doc1, doc2, doc3, doc4, doc5]
# training_labels = np.array([0, 0, 0, 1 ,1])
#
# doc6 = "predictable with no fun" # ?
#
# NBclassifier = NaiveBayesClassifier(n_gram=1)
# NBclassifier.train(training_set,training_labels)
#
# result = NBclassifier.predict(doc6)
# print(np.exp(result))

# Big file stuff
import string
import json

with open("reviews.json", mode="r", encoding="utf-8") as f:
  reviews = json.load(f)

sentiment_numerical_val = {
    'NEG': 0,
    'POS': 1
}

import pprint

def split_review_data(reviews, split=900, remove_punc=False, separation=" "):
    training_set = []
    training_labels = []
    validation_set = []
    validation_labels = []

    for i, r in enumerate(reviews):
        if i==0: print(str(r['content'])); print(dict(r).keys())
        cv = int(r["cv"])
        sent = sentiment_numerical_val[r["sentiment"]]
        content_string = ""
        for sentence in r["content"]:
            for word in sentence:
                content_string += word[0].lower() + separation

        if remove_punc:
            exclude = set(string.punctuation)
            content_string = ''.join(character for character in content_string if character not in exclude)

        if 0 < cv < split:
            training_set.append(content_string)
            training_labels.append(sent)
        else:
            validation_set.append(content_string)
            validation_labels.append(sent)

    return training_set, np.array(training_labels), validation_set, np.array(validation_labels)

def evaluate_predictions(validation_set,validation_labels,trained_classifier):
  correct_predictions = 0
  predictions_list = []
  prediction = -1

  for dataset,label in zip(validation_set, validation_labels):
    probabilities = trained_classifier.predict(dataset)
    if probabilities[0] >= probabilities[1]:
      prediction = 0
    elif  probabilities[0] < probabilities[1]:
      prediction = 1

    if prediction == label:
      correct_predictions += 1
      predictions_list.append("+")
      
    else:
      predictions_list.append("-")

  print("Predicted correctly {} out of {} ({}%)".format(correct_predictions,len(validation_labels),round(correct_predictions/len(validation_labels)*100,5)))
  return predictions_list, round(correct_predictions/len(validation_labels)*100)


training_set, training_labels, validation_set, validation_labels = split_review_data(reviews)

import time

start = time.time()

NBclassifier = NaiveBayesClassifier()
NBclassifier.train(training_set, training_labels, alpha=2)
results, acc = evaluate_predictions(validation_set, validation_labels, NBclassifier)

end = time.time()
print('Ran in {} seconds'.format(round(end - start, 5)))
----


+*Out[7]:*+
----
[[['Two', 'CD'], ['teen', 'JJ'], ['couples', 'NNS'], ['go', 'VBP'], ['to', 'TO'], ['a', 'DT'], ['church', 'NN'], ['party', 'NN'], [',', ','], ['drink', 'NN'], ['and', 'CC'], ['then', 'RB'], ['drive', 'NN'], ['.', '.']], [['They', 'PRP'], ['get', 'VBP'], ['into', 'IN'], ['an', 'DT'], ['accident', 'NN'], ['.', '.']], [['One', 'CD'], ['of', 'IN'], ['the', 'DT'], ['guys', 'NNS'], ['dies', 'VBZ'], [',', ','], ['but', 'CC'], ['his', 'PRP$'], ['girlfriend', 'NN'], ['continues', 'VBZ'], ['to', 'TO'], ['see', 'VB'], ['him', 'PRP'], ['in', 'IN'], ['her', 'PRP$'], ['life', 'NN'], [',', ','], ['and', 'CC'], ['has', 'VBZ'], ['nightmares', 'NNS'], ['.', '.']], [['What', 'WP'], ["'s", 'VBZ'], ['the', 'DT'], ['deal', 'NN'], ['?', '.']], [['Watch', 'VB'], ['the', 'DT'], ['movie', 'NN'], ['and', 'CC'], ['``', '``'], ['sorta', 'NN'], ["''", "''"], ['find', 'VB'], ['out', 'RP'], ['...', ':'], ['CRITIQUE', 'NNP'], [':', ':'], ['A', 'NNP'], ['mind-fuck', 'JJ'], ['movie', 'NN'], ['for', 'IN'], ['the', 'DT'], ['teen', 'NN'], ['generation', 'NN'], ['that', 'WDT'], ['touches', 'NNS'], ['on', 'IN'], ['a', 'DT'], ['very', 'RB'], ['cool', 'JJ'], ['idea', 'NN'], [',', ','], ['but', 'CC'], ['presents', 'VBZ'], ['it', 'PRP'], ['in', 'IN'], ['a', 'DT'], ['very', 'RB'], ['bad', 'JJ'], ['package', 'NN'], ['.', '.']], [['Which', 'WDT'], ['is', 'VBZ'], ['what', 'WP'], ['makes', 'VBZ'], ['this', 'DT'], ['review', 'NN'], ['an', 'DT'], ['even', 'RB'], ['harder', 'RBR'], ['one', 'CD'], ['to', 'TO'], ['write', 'VB'], [',', ','], ['since', 'IN'], ['I', 'PRP'], ['generally', 'RB'], ['applaud', 'VBP'], ['films', 'NNS'], ['which', 'WDT'], ['attempt', 'VBP'], ['to', 'TO'], ['break', 'VB'], ['the', 'DT'], ['mold', 'NN'], [',', ','], ['mess', 'NN'], ['with', 'IN'], ['your', 'PRP$'], ['head', 'NN'], ['and', 'CC'], ['such', 'JJ'], ['-LRB-', '-LRB-'], ['LOST', 'JJ'], ['HIGHWAY', 'NNP'], ['&', 'CC'], ['MEMENTO', 'NNP'], ['-RRB-', '-RRB-'], [',', ','], ['but', 'CC'], ['there', 'EX'], ['are', 'VBP'], ['good', 'JJ'], ['and', 'CC'], ['bad', 'JJ'], ['ways', 'NNS'], ['of', 'IN'], ['making', 'VBG'], ['all', 'DT'], ['types', 'NNS'], ['of', 'IN'], ['films', 'NNS'], [',', ','], ['and', 'CC'], ['these', 'DT'], ['folks', 'NNS'], ['just', 'RB'], ['did', 'VBD'], ["n't", 'RB'], ['snag', 'NN'], ['this', 'DT'], ['one', 'CD'], ['correctly', 'RB'], ['.', '.']], [['They', 'PRP'], ['seem', 'VBP'], ['to', 'TO'], ['have', 'VB'], ['taken', 'VBN'], ['this', 'DT'], ['pretty', 'RB'], ['neat', 'JJ'], ['concept', 'NN'], [',', ','], ['but', 'CC'], ['executed', 'VBD'], ['it', 'PRP'], ['terribly', 'RB'], ['.', '.']], [['So', 'RB'], ['what', 'WP'], ['are', 'VBP'], ['the', 'DT'], ['problems', 'NNS'], ['with', 'IN'], ['the', 'DT'], ['movie', 'NN'], ['?', '.']], [['Well', 'RB'], [',', ','], ['its', 'PRP$'], ['main', 'JJ'], ['problem', 'NN'], ['is', 'VBZ'], ['that', 'IN'], ['it', 'PRP'], ["'s", 'VBZ'], ['simply', 'RB'], ['too', 'RB'], ['jumbled', 'JJ'], ['.', '.']], [['It', 'PRP'], ['starts', 'VBZ'], ['off', 'RP'], ['``', '``'], ['normal', 'JJ'], ["''", "''"], ['but', 'CC'], ['then', 'RB'], ['downshifts', 'VBZ'], ['into', 'IN'], ['this', 'DT'], ['``', '``'], ['fantasy', 'NN'], ["''", "''"], ['world', 'NN'], ['in', 'IN'], ['which', 'WDT'], ['you', 'PRP'], [',', ','], ['as', 'IN'], ['an', 'DT'], ['audience', 'NN'], ['member', 'NN'], [',', ','], ['have', 'VBP'], ['no', 'DT'], ['idea', 'NN'], ['what', 'WP'], ["'s", 'VBZ'], ['going', 'VBG'], ['on', 'RP'], ['.', '.']], [['There', 'EX'], ['are', 'VBP'], ['dreams', 'NNS'], [',', ','], ['there', 'EX'], ['are', 'VBP'], ['characters', 'NNS'], ['coming', 'VBG'], ['back', 'RB'], ['from', 'IN'], ['the', 'DT'], ['dead', 'JJ'], [',', ','], ['there', 'EX'], ['are', 'VBP'], ['others', 'NNS'], ['who', 'WP'], ['look', 'VBP'], ['like', 'IN'], ['the', 'DT'], ['dead', 'JJ'], [',', ','], ['there', 'EX'], ['are', 'VBP'], ['strange', 'JJ'], ['apparitions', 'NNS'], [',', ','], ['there', 'EX'], ['are', 'VBP'], ['disappearances', 'NNS'], [',', ','], ['there', 'EX'], ['are', 'VBP'], ['a', 'DT'], ['looooot', 'NN'], ['of', 'IN'], ['chase', 'NN'], ['scenes', 'NNS'], [',', ','], ['there', 'EX'], ['are', 'VBP'], ['tons', 'NNS'], ['of', 'IN'], ['weird', 'JJ'], ['things', 'NNS'], ['that', 'WDT'], ['happen', 'VBP'], [',', ','], ['and', 'CC'], ['most', 'JJS'], ['of', 'IN'], ['it', 'PRP'], ['is', 'VBZ'], ['simply', 'RB'], ['not', 'RB'], ['explained', 'VBN'], ['.', '.']], [['Now', 'RB'], ['I', 'PRP'], ['personally', 'RB'], ['do', 'VBP'], ["n't", 'RB'], ['mind', 'VB'], ['trying', 'VBG'], ['to', 'TO'], ['unravel', 'VB'], ['a', 'DT'], ['film', 'NN'], ['every', 'DT'], ['now', 'RB'], ['and', 'CC'], ['then', 'RB'], [',', ','], ['but', 'CC'], ['when', 'WRB'], ['all', 'DT'], ['it', 'PRP'], ['does', 'VBZ'], ['is', 'VBZ'], ['give', 'VB'], ['me', 'PRP'], ['the', 'DT'], ['same', 'JJ'], ['clue', 'NN'], ['over', 'IN'], ['and', 'CC'], ['over', 'IN'], ['again', 'RB'], [',', ','], ['I', 'PRP'], ['get', 'VBP'], ['kind', 'NN'], ['of', 'IN'], ['fed', 'VBN'], ['up', 'RP'], ['after', 'IN'], ['a', 'DT'], ['while', 'NN'], [',', ','], ['which', 'WDT'], ['is', 'VBZ'], ['this', 'DT'], ['film', 'NN'], ["'s", 'POS'], ['biggest', 'JJS'], ['problem', 'NN'], ['.', '.']], [['It', 'PRP'], ["'s", 'VBZ'], ['obviously', 'RB'], ['got', 'VBN'], ['this', 'DT'], ['big', 'JJ'], ['secret', 'NN'], ['to', 'TO'], ['hide', 'VB'], [',', ','], ['but', 'CC'], ['it', 'PRP'], ['seems', 'VBZ'], ['to', 'TO'], ['want', 'VB'], ['to', 'TO'], ['hide', 'VB'], ['it', 'PRP'], ['completely', 'RB'], ['until', 'IN'], ['its', 'PRP$'], ['final', 'JJ'], ['five', 'CD'], ['minutes', 'NNS'], ['.', '.']], [['And', 'CC'], ['do', 'VBP'], ['they', 'PRP'], ['make', 'VBP'], ['things', 'NNS'], ['entertaining', 'JJ'], [',', ','], ['thrilling', 'JJ'], ['or', 'CC'], ['even', 'RB'], ['engaging', 'JJ'], [',', ','], ['in', 'IN'], ['the', 'DT'], ['meantime', 'NN'], ['?', '.']], [['Not', 'RB'], ['really', 'RB'], ['.', '.']], [['The', 'DT'], ['sad', 'JJ'], ['part', 'NN'], ['is', 'VBZ'], ['that', 'IN'], ['the', 'DT'], ['Arrow', 'NNP'], ['and', 'CC'], ['I', 'PRP'], ['both', 'DT'], ['dig', 'NN'], ['on', 'IN'], ['flicks', 'NNS'], ['like', 'IN'], ['this', 'DT'], [',', ','], ['so', 'IN'], ['we', 'PRP'], ['actually', 'RB'], ['figured', 'VBD'], ['most', 'JJS'], ['of', 'IN'], ['it', 'PRP'], ['out', 'RP'], ['by', 'IN'], ['the', 'DT'], ['half-way', 'NN'], ['point', 'NN'], [',', ','], ['so', 'RB'], ['all', 'DT'], ['of', 'IN'], ['the', 'DT'], ['strangeness', 'NN'], ['after', 'IN'], ['that', 'DT'], ['did', 'VBD'], ['start', 'VB'], ['to', 'TO'], ['make', 'VB'], ['a', 'DT'], ['little', 'JJ'], ['bit', 'NN'], ['of', 'IN'], ['sense', 'NN'], [',', ','], ['but', 'CC'], ['it', 'PRP'], ['still', 'RB'], ['did', 'VBD'], ["n't", 'RB'], ['the', 'DT'], ['make', 'VB'], ['the', 'DT'], ['film', 'NN'], ['all', 'DT'], ['that', 'IN'], ['more', 'JJR'], ['entertaining', 'JJ'], ['.', '.']], [['I', 'PRP'], ['guess', 'VBP'], ['the', 'DT'], ['bottom', 'JJ'], ['line', 'NN'], ['with', 'IN'], ['movies', 'NNS'], ['like', 'IN'], ['this', 'DT'], ['is', 'VBZ'], ['that', 'IN'], ['you', 'PRP'], ['should', 'MD'], ['always', 'RB'], ['make', 'VB'], ['sure', 'JJ'], ['that', 'IN'], ['the', 'DT'], ['audience', 'NN'], ['is', 'VBZ'], ['``', '``'], ['into', 'IN'], ['it', 'PRP'], ["''", "''"], ['even', 'RB'], ['before', 'IN'], ['they', 'PRP'], ['are', 'VBP'], ['given', 'VBN'], ['the', 'DT'], ['secret', 'JJ'], ['password', 'NN'], ['to', 'TO'], ['enter', 'VB'], ['your', 'PRP$'], ['world', 'NN'], ['of', 'IN'], ['understanding', 'NN'], ['.', '.']], [['I', 'PRP'], ['mean', 'VBP'], [',', ','], ['showing', 'VBG'], ['Melissa', 'NNP'], ['Sagemiller', 'NNP'], ['running', 'VBG'], ['away', 'RB'], ['from', 'IN'], ['visions', 'NNS'], ['for', 'IN'], ['about', 'RB'], ['20', 'CD'], ['minutes', 'NNS'], ['throughout', 'IN'], ['the', 'DT'], ['movie', 'NN'], ['is', 'VBZ'], ['just', 'RB'], ['plain', 'JJ'], ['lazy', 'JJ'], ['!!', 'NN']], [['Okay', 'UH'], [',', ','], ['we', 'PRP'], ['get', 'VBP'], ['it', 'PRP'], ['...', ':'], ['there', 'EX'], ['are', 'VBP'], ['people', 'NNS'], ['chasing', 'VBG'], ['her', 'PRP'], ['and', 'CC'], ['we', 'PRP'], ['do', 'VBP'], ["n't", 'RB'], ['know', 'VB'], ['who', 'WP'], ['they', 'PRP'], ['are', 'VBP'], ['.', '.']], [['Do', 'VB'], ['we', 'PRP'], ['really', 'RB'], ['need', 'VBP'], ['to', 'TO'], ['see', 'VB'], ['it', 'PRP'], ['over', 'IN'], ['and', 'CC'], ['over', 'IN'], ['again', 'RB'], ['?', '.']], [['How', 'WRB'], ['about', 'RB'], ['giving', 'VBG'], ['us', 'PRP'], ['different', 'JJ'], ['scenes', 'NNS'], ['offering', 'VBG'], ['further', 'JJ'], ['insight', 'NN'], ['into', 'IN'], ['all', 'DT'], ['of', 'IN'], ['the', 'DT'], ['strangeness', 'NN'], ['going', 'VBG'], ['down', 'RB'], ['in', 'IN'], ['the', 'DT'], ['movie', 'NN'], ['?', '.']], [['Apparently', 'RB'], [',', ','], ['the', 'DT'], ['studio', 'NN'], ['took', 'VBD'], ['this', 'DT'], ['film', 'NN'], ['away', 'RB'], ['from', 'IN'], ['its', 'PRP$'], ['director', 'NN'], ['and', 'CC'], ['chopped', 'VBD'], ['it', 'PRP'], ['up', 'RP'], ['themselves', 'PRP'], [',', ','], ['and', 'CC'], ['it', 'PRP'], ['shows', 'VBZ'], ['.', '.']], [['There', 'EX'], ['might', 'MD'], ["'ve", 'VB'], ['been', 'VBN'], ['a', 'DT'], ['pretty', 'RB'], ['decent', 'JJ'], ['teen', 'NN'], ['mind-fuck', 'NN'], ['movie', 'NN'], ['in', 'IN'], ['here', 'RB'], ['somewhere', 'RB'], [',', ','], ['but', 'CC'], ['I', 'PRP'], ['guess', 'VBP'], ['``', '``'], ['the', 'DT'], ['suits', 'NNS'], ["''", "''"], ['decided', 'VBD'], ['that', 'IN'], ['turning', 'VBG'], ['it', 'PRP'], ['into', 'IN'], ['a', 'DT'], ['music', 'NN'], ['video', 'NN'], ['with', 'IN'], ['little', 'JJ'], ['edge', 'NN'], [',', ','], ['would', 'MD'], ['make', 'VB'], ['more', 'JJR'], ['sense', 'NN'], ['.', '.']], [['The', 'DT'], ['actors', 'NNS'], ['are', 'VBP'], ['pretty', 'RB'], ['good', 'JJ'], ['for', 'IN'], ['the', 'DT'], ['most', 'JJS'], ['part', 'NN'], [',', ','], ['although', 'IN'], ['Wes', 'NNP'], ['Bentley', 'NNP'], ['just', 'RB'], ['seemed', 'VBD'], ['to', 'TO'], ['be', 'VB'], ['playing', 'VBG'], ['the', 'DT'], ['exact', 'JJ'], ['same', 'JJ'], ['character', 'NN'], ['that', 'IN'], ['he', 'PRP'], ['did', 'VBD'], ['in', 'IN'], ['AMERICAN', 'NNP'], ['BEAUTY', 'NNP'], [',', ','], ['only', 'RB'], ['in', 'IN'], ['a', 'DT'], ['new', 'JJ'], ['neighborhood', 'NN'], ['.', '.']], [['But', 'CC'], ['my', 'PRP$'], ['biggest', 'JJS'], ['kudos', 'NNS'], ['go', 'VBP'], ['out', 'RP'], ['to', 'TO'], ['Sagemiller', 'NNP'], [',', ','], ['who', 'WP'], ['holds', 'VBZ'], ['her', 'PRP$'], ['own', 'JJ'], ['throughout', 'IN'], ['the', 'DT'], ['entire', 'JJ'], ['film', 'NN'], [',', ','], ['and', 'CC'], ['actually', 'RB'], ['has', 'VBZ'], ['you', 'PRP'], ['feeling', 'VBG'], ['her', 'PRP$'], ['character', 'NN'], ["'s", 'POS'], ['unraveling', 'NN'], ['.', '.']], [['Overall', 'RB'], [',', ','], ['the', 'DT'], ['film', 'NN'], ['does', 'VBZ'], ["n't", 'RB'], ['stick', 'VB'], ['because', 'IN'], ['it', 'PRP'], ['does', 'VBZ'], ["n't", 'RB'], ['entertain', 'VB'], [',', ','], ['it', 'PRP'], ["'s", 'VBZ'], ['confusing', 'JJ'], [',', ','], ['it', 'PRP'], ['rarely', 'RB'], ['excites', 'VBZ'], ['and', 'CC'], ['it', 'PRP'], ['feels', 'VBZ'], ['pretty', 'RB'], ['redundant', 'JJ'], ['for', 'IN'], ['most', 'JJS'], ['of', 'IN'], ['its', 'PRP$'], ['runtime', 'NN'], [',', ','], ['despite', 'IN'], ['a', 'DT'], ['pretty', 'RB'], ['cool', 'JJ'], ['ending', 'VBG'], ['and', 'CC'], ['explanation', 'NN'], ['to', 'TO'], ['all', 'DT'], ['of', 'IN'], ['the', 'DT'], ['craziness', 'NN'], ['that', 'WDT'], ['came', 'VBD'], ['before', 'IN'], ['it', 'PRP'], ['.', '.']], [['Oh', 'UH'], [',', ','], ['and', 'CC'], ['by', 'IN'], ['the', 'DT'], ['way', 'NN'], [',', ','], ['this', 'DT'], ['is', 'VBZ'], ['not', 'RB'], ['a', 'DT'], ['horror', 'NN'], ['or', 'CC'], ['teen', 'JJ'], ['slasher', 'NN'], ['flick', 'NN'], ['...', ':'], ['it', 'PRP'], ["'s", 'VBZ'], ['just', 'RB'], ['packaged', 'VBN'], ['to', 'TO'], ['look', 'VB'], ['that', 'DT'], ['way', 'NN'], ['because', 'IN'], ['someone', 'NN'], ['is', 'VBZ'], ['apparently', 'RB'], ['assuming', 'VBG'], ['that', 'IN'], ['the', 'DT'], ['genre', 'NN'], ['is', 'VBZ'], ['still', 'RB'], ['hot', 'JJ'], ['with', 'IN'], ['the', 'DT'], ['kids', 'NNS'], ['.', '.']], [['It', 'PRP'], ['also', 'RB'], ['wrapped', 'VBD'], ['production', 'NN'], ['two', 'CD'], ['years', 'NNS'], ['ago', 'RB'], ['and', 'CC'], ['has', 'VBZ'], ['been', 'VBN'], ['sitting', 'VBG'], ['on', 'IN'], ['the', 'DT'], ['shelves', 'NNS'], ['ever', 'RB'], ['since', 'IN'], ['.', '.']], [['Whatever', 'WDT'], ['...', ':'], ['skip', 'VB'], ['it', 'PRP'], ['!', '.']]]
dict_keys(['cv', 'sentiment', 'content'])
Predicted correctly 166 out of 202 (82.17822%)
Ran in 0.73268 seconds
----


+*In[ ]:*+
[source, ipython3]
----

----


+*In[ ]:*+
[source, ipython3]
----

----
